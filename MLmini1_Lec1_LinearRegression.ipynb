{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLmini1-Lec1-LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNh/ZdQLBlQTfRaOHaejE4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearningMini-Summer1399/blob/master/MLmini1_Lec1_LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXO2Fa0YBjB5",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *mini* Course\n",
        "## PythonChallenge.ir\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "# Lecture 1 - Linear Regression\n",
        "<img src=\"https://github.com/M-H-Amini/MachineLearningMini-Summer1399/blob/master/stuff/W.jpg?raw=true\" width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IljETY4yFS5a",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The theoretical stuff has been discussed in the video lectures. Let's implement a little...\n",
        "\n",
        "First of all, we should import some modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9sWGnzX1xNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOo1VsyEBkcZ",
        "colab_type": "text"
      },
      "source": [
        "# Creating Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qc9FMDVpvls",
        "colab_type": "text"
      },
      "source": [
        "Let's create a simple one dimensional dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ltTDTTAn5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([np.linspace(10, 50, 15)])\n",
        "y = 2 + 1.5 * x +  10 * np.random.normal(0, 1, x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-SKelkBFx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x, y, 'rx')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAdoekrHBxhi",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression (Hand Coding!)\n",
        "Now, we implement our estimator just using **numpy**. In this method, we implement gradients calculation and weight updates (gradient descent) by hand!\n",
        "\n",
        "Let's implement estimator (hypothesis) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNAw7Z2pBdJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def h(x, w, has_bias=False):\n",
        "  if not has_bias:\n",
        "    x = np.concatenate((np.ones((1, x.shape[1])) ,x))\n",
        "  return np.dot(np.transpose(w), x)\n",
        "\n",
        "w = np.array([[1], [0.5]])\n",
        "print(h(np.array([[1, 2]]), w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiftUlS5Hd3R",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Data and Estimator Result\n",
        "It is exciting to see the performance with a simple function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3adT50oHsab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(x, y, w):\n",
        "  predicted = h(x, w)\n",
        "  plt.figure()\n",
        "  plt.plot(x[0:1,:], y, 'rx')\n",
        "  plt.plot(x[0], predicted[0], 'b-')\n",
        "  plt.show()\n",
        "\n",
        "w = np.array([[0], [0.2]])\n",
        "show(x, y, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN6ilNiRCavp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.0001\n",
        "\n",
        "def train_step(x, y, w):\n",
        "  x = np.concatenate((np.ones((1, x.shape[1])) ,x))\n",
        "  delta_w = -np.dot(x, np.transpose(y - h(x, w, True)))\n",
        "  w = w - alpha * delta_w\n",
        "  return w\n",
        "\n",
        "def cost(x, y, w):\n",
        "  return float(np.dot(y - h(x, w),np.transpose(y - h(x, w))) / (2*y.shape[1]))\n",
        "\n",
        "def train(x, y, max_iters=1000, min_cost=0.1, w=None, verbose=0):\n",
        "  if w is None:\n",
        "    w = np.random.rand(2, 1)\n",
        "  for i in range(max_iters):\n",
        "    index = np.random.randint(0, x.shape[1])\n",
        "    w = train_step(x[:, index:index+1], y[:, index:index+1], w)\n",
        "    if cost(x, y, w) < min_cost:\n",
        "      break\n",
        "    if verbose:\n",
        "      print('Iteration {}: W = '.format(i+1),np.transpose(w), 'Cost = ', cost(x, y, w))\n",
        "  print(\"Training Done...\")\n",
        "  print(\"Cost: {}\".format(cost(x, y, w)))\n",
        "  print(\"w = \", w.T)\n",
        "  return w\n",
        "\n",
        "w = train(x, y, max_iters=1000, min_cost=10 , verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRuSuINcL8MF",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Performance\n",
        "Let's see the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bMbot_eL7iX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(x.shape[1]):\n",
        "  print('Input: {:5.3f}, Target: {:5.3f}, Output: {:5.3f}'.format(x[:,i:i+1][0][0], y[:, i:i+1][0][0], h(x[:, i:i+1], w)[0][0]))\n",
        "\n",
        "show(x, y, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMMiyIS0Pc9I",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1kZYpzQKiV95eL6EZHL_CaE0Ca49MkLPO\" width=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLpibBqSAxd3",
        "colab_type": "text"
      },
      "source": [
        "# Normal Equation\n",
        "Use of normal equation, wherever possible, makes our life a lot easier! The main reason is that it is not an iterative method. You get the minimum in a few computations, instead of (maybe) thousands of iterations of last method. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7RT_0YBAwv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findWeights(x, y):\n",
        "  x = np.transpose(np.concatenate((np.ones((1, x.shape[1])),x)))\n",
        "  y = np.transpose(y)\n",
        "  w = np.dot(np.dot(np.linalg.inv(np.dot(x.T, x)), x.T), y)\n",
        "  return w\n",
        "\n",
        "w = np.random.rand(2,1)\n",
        "w = findWeights(x, y)\n",
        "show(x, y, w)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSN6yxUvC3iI",
        "colab_type": "text"
      },
      "source": [
        "# Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dREZiHiRDVMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx = np.array([np.linspace(-10, 10, 50)])\n",
        "yy = xx + 0.1*np.power(xx,2) + np.sin(xx) + np.random.randn(*xx.shape)\n",
        "w = np.array([[0],[0],[0],[0]])\n",
        "\n",
        "xxx = np.concatenate((xx, np.power(xx, 2), np.sin(xx)))\n",
        "print(xxx.shape, yy.shape)\n",
        "w = findWeights(xxx, yy)\n",
        "show(xxx, yy, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnuj_ynMPyvZ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=12Ain53U4GehBQgCzY0AKtAtG6kkyfhc0\" width=\"600\">\n"
      ]
    }
  ]
}